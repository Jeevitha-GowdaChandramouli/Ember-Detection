{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/0425_take6/annotations/0425take6.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "with open(\"data/0425_take6/annotations/0425take6_mod.json\", \"w\") as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/0425_take6/annotations/0425take6_mod.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "import random\n",
    "images_id_list = []\n",
    "for i in data['images']:\n",
    "  # print(i['id'])\n",
    "  images_id_list.append(i['id'])\n",
    "\n",
    "# print(len(images_id_list))\n",
    "train_set_ratio = 0.6\n",
    "splt_value = int(train_set_ratio*len(images_id_list))\n",
    "random.shuffle(images_id_list)\n",
    "train_data_id = images_id_list[:splt_value]\n",
    "test_val_data_id = images_id_list[splt_value:]\n",
    "val_set_ratio = 0.5 # 50% of the test+val images\n",
    "splt_value = int(train_set_ratio*len(test_val_data_id))\n",
    "random.shuffle(test_val_data_id)\n",
    "val_data_id = test_val_data_id[:splt_value]\n",
    "test_data_id = test_val_data_id[splt_value:]\n",
    "training_set_images = []\n",
    "val_set_images = []\n",
    "test_set_images = []\n",
    "for i in data['images']:\n",
    "  if i['id'] in train_data_id:\n",
    "    training_set_images.append(i)\n",
    "  elif i['id'] in val_data_id:\n",
    "    val_set_images.append(i)\n",
    "  else:\n",
    "    test_set_images.append(i)\n",
    "\n",
    "training_annotations = []\n",
    "val_annotations = []\n",
    "test_annotations = []\n",
    "for i in data['annotations']:\n",
    "  if i['image_id'] in train_data_id:\n",
    "    training_annotations.append(i)\n",
    "  elif i['image_id'] in val_data_id:\n",
    "    val_annotations.append(i)\n",
    "  else:\n",
    "    test_annotations.append(i)\n",
    "\n",
    "training_dataset = {}\n",
    "training_dataset['images'] = training_set_images\n",
    "training_dataset['annotations'] = training_annotations\n",
    "training_dataset['info'] = data['info']\n",
    "training_dataset['categories'] = data['categories']\n",
    "\n",
    "val_dataset = {}\n",
    "val_dataset['images'] = val_set_images\n",
    "val_dataset['annotations'] = val_annotations\n",
    "val_dataset['info'] = data['info']\n",
    "val_dataset['categories'] = data['categories']\n",
    "\n",
    "test_dataset = {}\n",
    "test_dataset['images'] = test_set_images\n",
    "test_dataset['annotations'] = test_annotations\n",
    "test_dataset['info'] = data['info']\n",
    "test_dataset['categories'] = data['categories']\n",
    "\n",
    "with open(\"data/0425_take6/annotations/ember_train_dataset.json\", \"w\") as file:\n",
    "    json.dump(training_dataset, file, indent=4)\n",
    "\n",
    "with open(\"data/0425_take6/annotations/ember_val_dataset.json\", \"w\") as file:\n",
    "    json.dump(val_dataset, file, indent=4)\n",
    "\n",
    "with open(\"data/0425_take6/annotations/ember_test_dataset.json\", \"w\") as file:\n",
    "    json.dump(test_dataset, file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mmdetection/data/0425_take6/annotations/ember_train_dataset.json\", \"r\") as file:\n",
    "    data_train = json.load(file)\n",
    "\n",
    "for i in data_train[\"images\"]:\n",
    "    source = os.path.join(\"mmdetection/data/0425_take6/imgs/\", i[\"file_name\"])\n",
    "    shutil.copy(source, \"mmdetection/data/0425_take6/train\")\n",
    "\n",
    "with open(\"mmdetection/data/0425_take6/annotations/ember_val_dataset.json\", \"r\") as file:\n",
    "    data_val = json.load(file)\n",
    "\n",
    "for i in data_val[\"images\"]:\n",
    "    source = os.path.join(\"mmdetection/data/0425_take6/imgs/\", i[\"file_name\"])\n",
    "    shutil.copy(source, \"mmdetection/data/0425_take6/val\")\n",
    "\n",
    "with open(\"mmdetection/data/0425_take6/annotations/ember_test_dataset.json\", \"r\") as file:\n",
    "    data_test = json.load(file)\n",
    "\n",
    "for i in data_test[\"images\"]:\n",
    "    source = os.path.join(\"mmdetection/data/0425_take6/imgs/\", i[\"file_name\"])\n",
    "    shutil.copy(source, \"mmdetection/data/0425_take6/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5336e623b002d26a1f558f113d43641ae3b5f9eedd6e0d06bd5a4d9e3d81c743"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
